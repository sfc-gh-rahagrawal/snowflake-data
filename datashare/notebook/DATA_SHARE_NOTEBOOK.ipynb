{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "x64xjrjlc4x6xczuqwb3",
   "authorId": "8094483995243",
   "authorName": "RAHUL.AGRAWAL@SNOWFLAKE.COM",
   "authorEmail": "Rahul.Agrawal@snowflake.com",
   "sessionId": "1f35d905-2043-4263-a545-35827d76519a",
   "lastEditTime": 1755150357414
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Libraries"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3acba-1067-44f4-8193-b26417a4def5",
   "metadata": {
    "name": "ParamInstruction",
    "collapsed": false
   },
   "source": "### Parameter Instruction\n\nIf calling the notebook from a task using EXECUTE NOTEBOOK MY_DATABASE.PUBLIC.MY_NOTEBOOK\nplease pass the following params\n\n- Environment\nThe values will be read internally by notebook as follows\nsys.argv = ['DEV']\n\nIf there are no params passed then the notebook will use the default values fro the config.json file\nand sys.argv will be blank\nsys.argv = []"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7390a5-b1af-4336-8bc5-e4bba277143b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "ReadConfig"
   },
   "outputs": [],
   "source": "import yaml\n\n# Load Configuration from file or string\nwith open(\"config.yaml\", \"r\") as f:\n    app_config = yaml.safe_load(f)\n\napp_config"
  },
  {
   "cell_type": "code",
   "id": "7d538482-ce01-4d25-8370-9ed24d39713c",
   "metadata": {
    "language": "python",
    "name": "EnvPrompt",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# sys.argv = [\"DEV\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c97e08-fb85-45fb-8700-8b9674d96bb1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Params"
   },
   "outputs": [],
   "source": "if len(sys.argv) > 0:\n    environment =  sys.argv[0]\n\nif environment == \"\":\n    raise RuntimeError(\"Please specify the target environment\")\n    \nV_source_account = app_config['connections'][environment]['source_account']\nV_share_name = app_config['connections'][environment]['share_name']\nV_source_environment_identifier = app_config['connections'][environment]['source_environment_identifier']\nV_target_environment_identifier = app_config['connections'][environment]['target_environment_identifier']\nV_execution_role = app_config['connections'][environment]['execution_role']\nV_log_table_namespace = app_config['connections'][environment]['log_table_namespace']\n\nV_organisation_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\n\nV_max_rows_to_load = app_config['max_rows_to_load']\nV_create_table_if_not_exists = app_config['create_table_if_not_exists']\nV_create_schema_if_not_exists = app_config['create_schema_if_not_exists']\n\nprint (f\"{V_organisation_name}.{V_source_account} | {V_share_name} | {V_source_environment_identifier} | {V_target_environment_identifier}\")\nprint (f\"{V_execution_role} | {V_create_schema_if_not_exists} | {V_create_table_if_not_exists}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e03123-9823-4482-abeb-4e87d2c62fc9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "ExecutionRole"
   },
   "outputs": [],
   "source": [
    "# Set Execution Role context\n",
    "sql = f\"USE ROLE {V_execution_role}\"\n",
    "print(sql)\n",
    "session.sql(sql).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02938198-c555-4cbc-9487-d444d43160df",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "ReadDataShareConfig"
   },
   "outputs": [],
   "source": "sql = f\"SHOW SHARES LIKE '{V_share_name}'\"\nshare = session.sql(sql).collect()\n\n# Access the COMMENT field from the first row\ncomment = share[0][\"comment\"] if share else None"
  },
  {
   "cell_type": "code",
   "id": "e5d53fe3-750c-46e6-9614-4cec80092f1d",
   "metadata": {
    "language": "python",
    "name": "ParseShareConfig",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# print(\"Comment:\", comment)\njson_comment = comment.replace(\"'\", '\"')\njson_data = json.loads(json_comment)\njson_data\n\ntable_details = json_data[\"tables\"]\ndatabase_name = json_data[\"database_name\"]\ntarget_database = database_name.replace(V_source_environment_identifier, V_target_environment_identifier)\nprint(f\"{database_name} --> {target_database}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2614038-ba4f-4ef6-abcd-fb18c287a6d5",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "CreateShareDB"
   },
   "outputs": [],
   "source": "# Create Shared Database\nseparator = \"\" if V_share_name.startswith(\"_\") else \"_\"\nsource_shared_db = f\"READER{separator}{V_share_name}\"\nsql = f\"CREATE OR REPLACE DATABASE {source_shared_db} FROM SHARE {V_organisation_name}.{V_source_account}.{V_share_name}\"\nprint(sql)\nsession.sql(sql).collect()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0108b-119f-40ef-a59c-52cd4c07432d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "LogDataShareDefinition"
   },
   "outputs": [],
   "source": "def data_share_log_table_info(log_table_namespace, share_name_id, target_db, target_schema, target_table, date_col, filter_date, retention_date, table_config, refresh_ts):\n\n    filter_date = 'NULL' if filter_date == '' else f\"'{filter_date}'\"\n    config_json = json.dumps(table_config)  # converts dict to JSON string with double quotes\n    config_sql_value = f\"PARSE_JSON('{config_json}')\"\n\n    log_sql = f\"\"\"\n    INSERT INTO {log_table_namespace}.DATA_COPY_TABLE_CATALOG (\n        SHARE_NAME_ID, DATABASE_NAME, SCHEMA_NAME, TABLE_NAME, \n        FILTER_DATE_COLUMN, FILTER_DATE, RETENTION_DATE, TABLE_CONFIG, REFRESH_TS)\n        SELECT\n            '{share_name_id}',\n            '{target_db}',\n            '{target_schema}',\n            '{target_table}',\n            '{date_col}',\n            {filter_date},\n            '{retention_date}',\n            {config_sql_value},\n            '{refresh_ts}'\n    \"\"\"\n    \n    session.sql(log_sql).collect()    "
  },
  {
   "cell_type": "code",
   "id": "8abddac9-96f4-4903-841c-061bc45c0970",
   "metadata": {
    "language": "python",
    "name": "LogTableDefinition",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def data_share_log_share_info(log_table_namespace, share_name_id, share_config, refresh_ts):\n\n    config_json = json.dumps(share_config)  # converts dict to JSON string with double quotes\n    config_sql_value = f\"PARSE_JSON('{config_json}')\"\n\n    log_sql = f\"\"\"\n    INSERT INTO {log_table_namespace}.DATA_COPY_SHARE_CATALOG (SHARE_NAME_ID, DATA_SHARE_CREATOR_ID, DATA_SHARE_REQUESTOR_ID, DATA_SHARE_REQUEST_REASON, DATA_SHARE_CONFIG, REFRESH_TS)\n        SELECT\n            '{share_name_id}',\n            '{share_config[\"share_created_by\"]}',\n            '{share_config[\"share_requested_by\"]}',\n            '{share_config[\"share_requested_reason\"]}',\n            {config_sql_value},\n            '{refresh_ts}'\n    \"\"\"\n    \n    session.sql(log_sql).collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c22cabb8-41f4-4d8f-89ca-d0be47124371",
   "metadata": {
    "language": "python",
    "name": "MaskDataShareColumns"
   },
   "outputs": [],
   "source": "def mask_data_share_columns(columnlist, data_share_config, col_type_map, pi_column_list):\n    \"\"\"\n    Apply masking based on data_share_config and replace PI columns with '*',\n    using data type logic for both cases.\n    \n    Args:\n        columnlist (list): List of column names (or SQL expressions).\n        data_share_config (dict): Config containing mask rules.\n        col_type_map (dict): Column data types.\n        pi_column_list (list): List of columns considered PI.\n    \n    Returns:\n        list: Updated column list with masking applied.\n    \"\"\"\n    updated_column_list = []\n    \n    for col in columnlist:\n        col_lower = col.lower()\n        pre_transformed = \" as \" in col_lower\n        column_expression = col\n        column_data_type = col_type_map.get(col, \"\").lower()\n\n        # Find the masking rule for the current column (col)\n        mask_info = next(\n            (m for m in data_share_config.get(\"mask\", {}).get(\"columns\", [])\n            if m[\"mask_column\"].lower() == col_lower),\n            None\n        )\n\n        # If masking found\n        if mask_info:\n            masked_tag = mask_info[\"masked_tag\"]\n    \n            if masked_tag.startswith(\"==\"):\n                # Special masking from config\n                expression_type = masked_tag[2:].lower()\n                masking_expression = app_config.get(\"masking_expression\", {})\n                regexp = masking_expression.get(expression_type, masking_expression.get(\"default\"))\n                column_expression = f\"{regexp} AS {col}\"\n    \n            elif masked_tag.startswith(\"=\"):\n                # SQL expression provided directly\n                column_expression = f\"{masked_tag[1:]} AS {col}\"\n    \n            else:\n                # Hardcoded replacement value with data type logic\n                if any(t in column_data_type for t in [\"number\", \"int\", \"float\", \"decimal\", \"boolean\"]):\n                    column_expression = f\"{masked_tag} AS {col}\" # numeric: no quotes\n                else:\n                    column_expression = f\"'{masked_tag}' AS {col}\" # string: with quotes\n    \n            # Replace placeholder 'val' with column name\n            column_expression = column_expression.replace(\"val\", col)\n    \n        # --- Step 2: Apply PI column masking using data type logic ---\n        elif not pre_transformed:\n            match = any(pi_col.lower() in col_lower for pi_col in pi_column_list)\n            if match:\n                if any(t in column_data_type for t in [\"number\", \"int\", \"float\", \"decimal\", \"boolean\"]):\n                    column_expression = f\"{app_config['default_replacement_values']['number']} AS {col}\" # numeric: no quotes\n                elif any(t in column_data_type for t in [\"date\", \"datetime\"]):\n                    column_expression = f\"DATE '{app_config['default_replacement_values']['date']}' AS {col}\" # date\n                elif any(t in column_data_type for t in [\"timestamp\", \"timestamp_ntz\", \"timestamp_ltz\", \"timestamp_tz\"]):\n                    column_expression = f\"TIMESTAMP '{app_config['default_replacement_values']['timestamp']}' AS {col}\" # timestamp\n                else:\n                    column_expression = f\"'{app_config['default_replacement_values']['text']}' AS {col}\" # string: with quotes\n            # print (f\"{col} as {column_data_type} : {column_expression}\")\n    \n        updated_column_list.append(column_expression)\n\n    return updated_column_list",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "425a1917-18d6-4d2d-9abf-6c2a7017e1c1",
   "metadata": {
    "language": "python",
    "name": "FetchPIColumnlist",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd;\npi_column_list = session.sql(f\"SELECT COLUMN_NAME FROM {V_log_table_namespace}.DATA_COPY_PI_COLUMNS\").toPandas()[\"COLUMN_NAME\"].str.lower().tolist()\n\npi_column_list",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8541033-6895-4a5b-9be2-e68a309f986f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "LoadShareTables"
   },
   "outputs": [],
   "source": "from datetime import datetime\n\n# Define the new mask column list\nrefresh_ts = datetime.utcnow()\nshare_name_id = V_share_name + \"_\" + refresh_ts.strftime(\"%Y%m%d%H%M\")\n\n# Log for Share\ndata_share_log_share_info(V_log_table_namespace, share_name_id, json_data, refresh_ts)\n\nfor table_full_name, share_config in table_details.items():\n    schema_name, table_name = table_full_name.split('.')\n\n    column_sql = f\"\"\"\n        SELECT COLUMN_NAME, DATA_TYPE\n        FROM {source_shared_db}.INFORMATION_SCHEMA.COLUMNS\n        WHERE TABLE_SCHEMA = '{schema_name}' AND TABLE_NAME = '{table_name}'\n        ORDER BY ORDINAL_POSITION\n    \"\"\"\n\n    # Convert dataframe to pandas list\n    df_pd = session.sql(column_sql).to_pandas()\n\n    # Create a lookup for column data types\n    col_type_map = dict(zip(df_pd[\"COLUMN_NAME\"], df_pd[\"DATA_TYPE\"]))\n\n    # Original column list (raw, unchanged)\n    col_list = df_pd[\"COLUMN_NAME\"].tolist()\n    raw_cols = \", \".join(col_list)\n\n    # Apply masking based on the configuration from App    \n    col_list = mask_data_share_columns(col_list, share_config, col_type_map, pi_column_list)\n\n    val_cols = \", \".join(col_list)\n\n    target_table = f\"{target_database}.{schema_name}.{table_name}\"\n    source_table = f\"{source_shared_db}.{schema_name}.{table_name}\"\n\n    select_sql = f\"SELECT {val_cols} FROM {source_table}\"\n    # Apply filter if provided\n    if \"filter\" in share_config:\n        date_column = share_config['filter']['date_column']\n        filter_date = json_data['filter_date']\n        select_sql += f\" WHERE TO_DATE({date_column}) > '{filter_date}'\"\n    else:\n        date_column = ''\n        filter_date = ''\n\n    if V_max_rows_to_load != \"0\":\n        select_sql += f\" limit {V_max_rows_to_load}\"\n\n    execute_sql = \"\"\n    if V_create_schema_if_not_exists:\n        execute_sql += f\"CREATE OR ALTER SCHEMA {target_database}.{schema_name}; \"\n\n    print(f\"Loading table {target_table}\")\n    print(f\"{select_sql}\")\n    \n    if V_create_table_if_not_exists:\n        execute_sql += f\"CREATE OR REPLACE TABLE {target_table} AS {select_sql}; \"\n    else:\n        execute_sql += f\"TRUNCATE TABLE {target_table};\"\n        execute_sql += f\"INSERT INTO {target_table} ({raw_cols}) {select_sql}; \"\n\n    session.sql(\"ALTER SESSION SET MULTI_STATEMENT_COUNT = 0\").collect()\n    session.sql(execute_sql).collect()\n\n    data_share_log_table_info(\n        V_log_table_namespace,\n        share_name_id,\n        target_database,\n        schema_name,\n        table_name,\n        date_column,\n        filter_date,\n        json_data['data_retention_date'],\n        share_config,\n        refresh_ts\n    )\n\nprint(f\"Finished loading tables to database {target_database}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd37f07-f4e3-4e19-85a5-557546147c4c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "SeeTableLogInfo"
   },
   "outputs": [],
   "source": "df = session.sql(f\"select * from {V_log_table_namespace}.DATA_COPY_TABLE_CATALOG where share_name_id = '{share_name_id}' order by record_id\").collect()\ndf"
  },
  {
   "cell_type": "code",
   "id": "a3de8df1-bedd-4ffa-9c73-474ba72e5025",
   "metadata": {
    "language": "python",
    "name": "SeeShareLogInfo",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"select * from {V_log_table_namespace}.DATA_COPY_SHARE_CATALOG where share_name_id = '{share_name_id}' order by record_id\").collect()\ndf",
   "execution_count": null
  }
 ]
}